cloud computing services:
1)Infrastructure-as-a-Service (IaaS),
2)Platforms-as-a-Service (PaaS), and
3)Software-as-a-Service (SaaS)

EC2 Instance
============
Reserved Instances
	– Reduce your Amazon EC2 costs by making a commitment to a consistent
	instance configuration,including instance type and Region, for a term
	of 1 or 3 years.
Spot Instances
	– Request unused EC2 instances, which can reduce your Amazon EC2
	costs significantly.
	- Types
		- Regular spot pricing—instances can be terminated with 2 minutes notice.
		- Defined duration—you can get a spot instance guaranteed to run for a
		  period of 1-6 hours.
		  The longer the defined duration, the lower the discount provided for the spot instance.

ec2 types
1) General Purpose
2) Compute Optimized
3) Memory Optimized
4) Accelerated Computing
5) Storage Optimized
6) Instance Features

boto3
=====
- boto3 is built on top of botocore
	- client is for lower-level interactions
	- resource for higher-level object oriented abstractions
	- waiters are polling the status of specific resource
		- say, when creating ec2 instance, waiting till it reaches "Running" state
	- collections indicate a group of resources such as a group of s3 objects
	  in a bucket, or a group of SQS queues
		- It helps to perform some action on those groups

ec2 vs Lambda
=============
- Lambda is suitable for event-driven programming, whereas
	EC2 is suitable for more tailored solutions
- AWS EC2 is sutable for
	- hosting web sites
	- developing and testing applications or complex environments
	- high performance computing
	- disaster recovery
- And, Lambda is suitable for
	- Automating tasks
	- Processing objects uploaded to Amazon S3
	- Real-time log analyzing
	- Real-time filtering and transforming data

Lambda
=======
- Lambda Triggers
	API Gateway
	AWS IoT
	Alexa Skills Kit
	Alexa Smart Home
	Application Load Balancer
	CloudFront
	CloudWatch Events
	CloudWatch Logs
	CodeCommit
	Cognito Sync Trigger
	DynamoDB
	Kinesis
	S3
	SNS
	SQS

- cold start lambda
	- Lambda has better latency per request than EC2, but for first request, due to cold start,
	it is significantly slower.
	- To reduce this cold start, Earlier, i used to fire a dumy request periodically.
	- Also, we can assign provisioned concurrency, which means keeping a certain number of
	function containers ready for invocations.

- Lambda layer
	- It is an archive containing additional code, such as libraries, dependencies, or
	  even custom runtimes.
	- When you include a layer in a function, the contents are extracted to the /opt
	  directory in the execution environment.

	- For a Lambda function, there is a maximum of 5 layers and a maximum size
	  for all layers of 250 MB (uncompressed).
	  This maximum applies regardless of whether you are using an official AWS
	  runtime or a custom runtime.
	  The Application Security layer size is about 30 MB.

- chalice framework
	- local development setup for working with AWS Lambdas

- AWS Lambda Performance Optimizaton
	- increasing RAM => faster execution => same price.
	- Watch out for function size to reduce the cold start durations.
	- Split complex processes into separate functions to save money and gain speed.
	- When possible, execute code in parallel.
	- Reusing connections with Keep-Alive.

- Lambda Cold Start
	- https://www.simform.com/blog/lambda-cold-starts/

- AWS Lambda Advantages
	- Reduced Cost of Execution
	- Improved Application Resiliency

- AWS Lambda Limitations
	- The disk space (ephemeral) is limited to 512 MB.
	- The default deployment package size is 50 MB.
	- The memory range is from 128 to 3008 MB.
	- The maximum execution timeout for a function is 15 minutes*.
	- Requests limitations by Lambda:
		- Request and response (synchronous calls) body payload size can be up to to 6 MB.
		- Event request (asynchronous calls) body can be up to 128 KB.
	- More Complex Call Patterns
	- No Control Over Environment

- AWS Lambda event source mappings
	- An event source mapping is a Lambda resource that reads from an event source and
	invokes a Lambda function.
	- we can use event source mappings to process items from a stream or queue in services
	that don't invoke Lambda functions directly.
	- Lambda provides event source mappings for
		- Amazon DynamoDB
		- Amazon Kinesis
		- Amazon MQ
		- Amazon Managed Streaming for Apache Kafka (Amazon MSK)
		- Self-managed Apache Kafka


Amazon Simple Queue Service (Amazon SQS)
- AWS Lambda Examples
	- say, for Returning a message

	def lambda_handler(event, context):
		message = 'Hello {} {}!'.format(event['first_name'], event['last_name'])
		return {
			'message' : message
		}

	- The first argument is the event object.
	  An event is a JSON-formatted document that contains data for a Lambda function
	  to process. The Lambda runtime converts the event to an object and passes it to
	  your function code. It is usually of the Python dict type. It can also be list,
	  str, int, float, or the NoneType type.
	- The event object contains information from the invoking service.
	  When you invoke a function, you determine the structure and contents of the event.
	  When an AWS service invokes your function, the service defines the event structure.
	- The second argument is the context object.
	  A context object is passed to your function by Lambda at runtime.
	  This object provides methods and properties that provide information about the
	  invocation, function, and runtime environment.

	- AWS lambda can be invoked both synchronously or asynchronously
	  In synchronous invocation, lambda runs the function and waits for response.
		 when function completes, lambda returns response from the function's code with
		 additional data, such as the version of the function that was invoked.

		AWS CLI command for the same:
			aws lambda invoke --function-name my-function --payload '{ "key": "value" }' response.json

	  In asynchronous invocation, we dont wait for function response.
		you handoff event to lambda and handles rest.
		we configure how Lambda handles errors, and can send invocation records to a downstream
		resource to chain together components of your application.
		AWS services like S3 and SNS invoke functions asynchronously to process the events.
		Error handling for asynchronous events:
		we can configure
			1) Maximum age of event – The maximum amount of time Lambda retains an event
							 in the asynchronous event queue, up to 6 hours.
			2) Retry attempts – The number of times Lambda retries when the function
							 returns an error, between 0 and 2

		AWS CLI command:
			aws lambda invoke --function-name my-function  \
				  --invocation-type Event --cli-binary-format raw-in-base64-out \
						  --payload '{ "key": "value" }' response.json


AWS Lambda Context properties

	function_name 			– The name of the Lambda function.
	function_version 		– The version of the function.
	invoked_function_arn 	– The Amazon Resource Name (ARN) that's used to invoke the function.
								Indicates if the invoker specified a version number or alias.
	memory_limit_in_mb 		– The amount of memory that's allocated for the function.
	aws_request_id 			– The identifier of the invocation request.
	log_group_name 			– The log group for the function.
	log_stream_name 		– The log stream for the function instance.

	identity – (mobile apps) Information about the Amazon Cognito identity that authorized the request.
		cognito_identity_id 	– The authenticated Amazon Cognito identity.
		cognito_identity_pool_id– The Amazon Cognito identity pool that authorized the invocation.

	client_context – (mobile apps) Client context that's provided to Lambda by the client application.
		client.installation_id
		client.app_title
		client.app_version_name
		client.app_version_code
		client.app_package_name
		custom – A dict of custom values set by the mobile client application.
		env – A dict of environment information provided by the AWS SDK.

- AWS Lambda Vs Glue
	- Lambda can use a number of different languages (Node.js, Python, Go, Java, etc.)
	  whereas Glue can only execute jobs using Scala or Python code.
	- Lambda can execute code from triggers by other services (SQS, Kafka, DynamoDB,
	  Kinesis, CloudWatch, etc.) vs. Glue which can be triggered by lambda events,
	  another Glue jobs, manually or from a schedule.
	- Lambda runs much faster for smaller tasks vs. Glue jobs which take longer to
	  initialize due to the fact that it's using distributed processing. That being
	  said, Glue leverages its parallel processing to run large workloads faster than Lambda.
	- Lambda looks to require more complexity/code to integrate into data sources
	  (Redshift, RDS, S3, DBs running on ECS instances, DynamoDB, etc.) while Glue
	  can easily integrate with these. However, with the addition of Step Functions,
	  multiple lambda functions can be written and ordered sequentially due reduce
	  complexity and improve modularity where each function could integrate into a
	  aws service (Redshift, RDS, S3, DBs running on ECS instances, DynamoDB, etc.)
	- Glue looks to have a number of additional components, such as Data Catalog which
	  is a central metadata repository to view your data, a flexible scheduler that
	  handles dependency resolution/job monitoring/retries, AWS Glue DataBrew for
	  cleaning and normalizing data with a visual interface, AWS Glue Elastic Views
	  for combining and replicating data across multiple data stores, AWS Glue Schema
	  Registry to validate streaming data schema.

- AWS Glue
	- https://docs.aws.amazon.com/glue/latest/dg/add-job.html
	- https://docs.aws.amazon.com/glue/latest/dg/workflows_overview.html
	- AWS Glue connectors
		- Amazon S3
		- JDBC
			- Amazon Redshift
			- Amazon Relational Database Service (Amazon RDS)
		- Amazon DocumentDB
		- DynamoDB
		- Kafka
		- Amazon Kinesis
		- MongoDB
		- Network (designates a connection to a data source within an
					Amazon Virtual Private Cloud environment (Amazon VPC))

- ETL Jobs
	- I have created ETLs jobs like say,
		Users can connect to an endpoint, from where request goes via
			AWS Cognito for authentication , Then
			AWS API Gateway and then
			aws lambda and from there
			it can make AWS Athena queries on top of s3 buckets
			and reply that response in JSON

- RDS Proxy
	-RDS Proxy acts as an intermediary between your application and an RDS database.
	- RDS Proxy establishes and manages the necessary connection pools to your database
	  so that your application creates fewer database connections.
	- It connection pooling necessary for scaling many simultaneous connections
	  created by concurrent Lambda functions.

- dead letter queue
	- A dead-letter queue is an Amazon SQS queue that an Amazon SNS subscription can
	target for messages that can't be delivered to subscribers successfully.
	- Messages that can't be delivered due to client errors or server errors are held
	in the dead-letter queue for further analysis or reprocessing.

- AWS Redshift
	- Materialized View
		- It is similar to the db views for RDBMS
		- useful for speeding up queries that are predictable and repeated.
		- A materialized view contains a precomputed result set, based on an SQL query
		over one or more base tables.
		- It returns the precomputed results from the materialized view, without having
		to access the base tables at all.
	- Load CSV to Redshift
		1) Create the schema on Amazon Redshift.
		2) Load the CSV file to Amazon S3 bucket using AWS CLI or the web console.
		3) Import the CSV file to Redshift using the COPY command.
		4) Generate AWS Access and Secret Key in order to use the COPY command.
	  - Also, we can autoload using a 3rd party tool, called Skyvia

AWS DynamoDB
	is a fully managed proprietary NoSQL database
	service that provides fast and predictable performance with seamless scalability.
	It supports key-value and document data structures
	DynamoDB allows users to create tables for your database to store
	and retrieve any data volume and to support any request traffic level.

	LSI - allows you to perform a query on a single Hash-Key while using multiple
			different attributes to "filter" or restrict the query.
	GSI - allows you to perform queries on multiple Hash-Keys in a table, but costs
			extra in throughput, as a result.

	DynamoDB Streams is a powerful service that you can combine with other AWS services
	to solve many similar issues.
	When you enable DynamoDB Streams, it captures a time-ordered sequence of item-level
	modifications in a DynamoDB table and durably stores the information for up to 24 hours.

	projection Expressions
		- When we use GetItem, Query or Scan, we get data with all item attributes, by default.
		- To get only some specific attributes, we use projection expression.
		- It is a string that identifies the attributes we want.

AWS Athena
	- Its a interactive query service for querying on S3 using standard SQL
	- Performance Tuning Amazon Athena
		1. Partition the data
			- means, dividing the table into parts and keeping the related data together based on columns value like date, country, region, etc.
			- As partitions act as virtual columns, it helps reduce the amount of data scanned per query, thereby improving performance.
			- Also, we can specify filters on these patitions, similar to on columns, to refine the queries.

		2. Bucket the data
			- means, to bucket the data within a single partition. With bucketing,
			we can specify one or more columns containing rows that we want to group together,
			and put those rows into multiple buckets.
			- This helps to query only the bucket that we need to read when the bucketed columns value is specified,
			which can dramatically reduce the number of rows of data to read, which in turn reduces the cost of running the query.

		3. Use compression
			- using either BZIP2, DEFLATE, Gzip, LZ4, LZO, Snappy, Zlib, Zstd, etc for the compression
			- compression the files reduces the file sizes, which reduces the data scanned from S3,
			  resulting in lower cost of running queries. It , inturn, reduces the network traffic between Amazon s3 to Athena.

		4. Optimize file size
		5. Optimize columnar data store generation

Amazon Athena Workgroups are resource types, used to separate query execution and query
history between Users, Teams, or Applications running under the same AWS account.
Because Workgroups act as resources, you can use resource-based policies to control access
to a Workgroup.

I have experience migrating applications and data, from on-prem to cloud



AWS IAM
-------
	- IAM roles define the set of permissions for making AWS service request
	- IAM policies define the permissions that you will require.


	- Admin or root user for the account can create IAM identities.
	- An IAM identity provides access to an AWS account.
	- user group is a collection of IAM users managed as a unit.
	- IAM identity represents a user, and can be authenticated and then authorized to
	  perform actions in AWS.
	  Each IAM identity can be associated with one or more policies.

	- Policies determine what actions a user, role, or member of a user group can perform,
	  on which AWS resources, and under what conditions.
		- Identity-based policies are permissions policies that you attach to an IAM identity,
		  such as an IAM user, group, or role.
		- Resource-based policies are permissions policies that you attach to a resource such
		  as an Amazon S3 bucket or an IAM role trust policy.

	- Identity-based policies are attached to an IAM user, group, or role.
		- Identity-based policies can be managed or inline.
	- Resource-based policies are attached to a resource.
		- We can attach resource-based policies to
			Amazon S3 buckets,
			Amazon SQS queues,
			VPC endpoints, and
			AWS Key Management Service encryption keys.
		- With resource-based policies, we can specify who has access to the resource and what actions they can perform on it.
	- Resource-based policies Vs resource-level permissions
		- We can attach resource-based policies directly to a resource
		- Resource-level permissions refer to ability to use ARNs to specify individual resources in a policy.

	Identify Based Policies
		Effect 	– whether to allow or deny the action(s)
		Action 	– the API(s) the policy applied to requests on resources (‘*’ means wildcard)
		Resource– Identifier of the resource(s) to which the policy applies.
		          Resources are identified by an Amazon Resource Name (ARN), or by wildcard.

			{
				"Version": "2012-10-17",
				"Statement": [
					{
						"Effect": "Allow",
						"Action": [
							"s3:Get*",
							"s3:List*"
						],
						"Resource": "*"
					}
				]
			}
	Resource-based Policies
		Resource-based policies grant permissions to the principal that is specified in the policy.
		They specify who or what can invoke an API from a resource to which the policy is attached.
		{
		  "Version": "2012-10-17",
		  "Id": "default",
		  "Statement": [
			{
			  "Sid": "s3-event-cezary_for_lambda-s3",
			  "Effect": "Allow",
			  "Principal": {
				"Service": "s3.amazonaws.com"
			  },
			  "Action": "lambda:InvokeFunction",
			  "Resource": "arn:aws:lambda:eu-west-1:1234567890:function:lambda-s3",
			  "Condition": {
				"StringEquals": {
				  "AWS:SourceAccount": "1234567890:"
				},
				"ArnLike": {
				  "AWS:SourceArn": "arn:aws:s3:::test-bucket-cezary"
				}
			  }
			}
		  ]
		}


RDS vs DynamoDb
----------------
- Amazon RDS is relational, whereas DynamoDB is a NoSQL database engine.
- DynamoDB can support tables of any size, where as in RDS, the storage size changes
	based on the database engine used.
- Storing data in DyanmoDb costs more, compared to RDS or Aurora.
- DynamoDb is very fast as it is key-value database

- DynamoDb should not be used:
	- When multi-item or cross table transactions are required.
	- When complex queries and joins are required.
	- When real-time analytics on historic data is required.

SNS vs SQS
==========
SNS - sends messages to the subscriber using push mechanism and no need of pull.
SQS - it is a message queue service used by distributed applications to exchange
		messages through a polling model, and can be used to decouple sending and
		receiving components.


AWS Limits
==========
	Lambda Environment variables limit is not per function; but overall @ no more than 4KB
		   disk space (ephemeral) is limited to 512 MB
		   default deployment package size is 50 MB
		   memory range is from 128 to 3008 MB
		   maximum execution timeout for a function is 15 minutes
		   3000 concurrent request at time. If exceeded, requsts will throttle until lambda scales by 500 per minute


CloudFormation
===============
- intrinsic function
	- built-in functions that enable you to assign values to properties that are only available
	  at runtime.
	- we can use intrinsic functions in templates, to assign values to properties that are not
	  available until runtime.
	- Example
		Fn::Base64
		Fn::Cidr
		Condition functions
		Fn::FindInMap
		Fn::GetAtt
		Fn::GetAZs
		Fn::ImportValue
		Fn::Join
		Fn::Select
		Fn::Split
		Fn::Sub
		Fn::Transform

Stack Vs Stackset CloudFormation
- A stack set lets you create stacks in AWS accounts across AWS Regions by using a single AWS CloudFormation template.
  A stack set's CloudFormation template defines all the resources in each stack.
- A stack instance refers to a stack in a target account within an AWS Region and is associated with only one stack set.


boto3
------
- boto3 is built on top of botocore
	- client is for lower-level interactions
	- resource for higher-level object oriented abstractions
	- waiters are polling the status of specific resource
		- say, when creating ec2 instance, waiting till it reaches "Running" state
	- collections indicate a group of resources such as a group of s3 objects
	  in a bucket, or a group of SQS queues
		- It helps to perform some action on those groups

- List files in s3 bucket
	import boto3
	s3 = boto3.resource('s3')

	## Bucket to use
	bucket = s3.Bucket('my-bucket')

	## List objects within a given prefix
	for obj in bucket.objects.filter(Delimiter='/', Prefix='fruit/'):
		print(obj.key)

	Output:

		fruit/apple.txt
		fruit/banana.txt

AWS Secrets Manager
- Rotate secrets safely ( we can keep expiry and rotate values whenever needed )
- Manage access with fine-grained policies ( we can create a policy that enables developers to retrieve secrets values )
- Secure and audit secrets centrally ( it gives audit trail how many used from which account )
- Pay as you go ( No of secret value and no of API calls made for retrieval )
- Easily replicate secrets to multiple regions ( cross regions access is allow )

- It enables to rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle.
- secret rotation with built-in integration for Amazon Relational Database Service (Amazon RDS), Amazon Redshift,
and Amazon DocumentDB.
- Also, the service is extensible to other types of secrets, including API keys and OAuth tokens.
- In addition, Secrets Manager enables you to control access to secrets using fine-grained permissions and audit secret rotation
centrally for resources in the AWS Cloud, third-party services, and on-premises.

- To access the secrets manager, we can use either
	- AWS credentials ( combination of access key and secret key )
	- AWS SDK ( server side SDK or client side SDK

s3 classification
-----------------
1) s3 standard
		- for frequently accessed data
2) s3 Intelligent-Tiering
		- for automatic cost savings for data with unknown or changing access patterns
3) s3 Standard-IA  (Infrequent Access)
		- for less frequently accessed data
4) s3 One Zone-IA
		- for less frequently accessed data
5) s3 Glacier Instant Retrieval
		- for archive data that needs immediate access
6) s3 Glacier Flexible Retrieval(formerly S3 Glacier)
		- for rarely accessed long-term data that does not require immediate access
7) s3 Glacier Deep Archive
		- for long-term archive and digital preservation with retrieval in hours at the lowest cost storage in the cloud
8) s3 Output
		- storage class to store your S3 data on premises, when we cant store data in AWS any complience

Once an S3 Lifecycle policy is set, your data will automatically transfer to a different storage class
without any changes to your application.

we can create life cycle rules to delete files from a specific folder, like
	older than 30 days, etc

AWS account security tools
--------------------------

- AWS IAM (Identity & Access Management)
	- Enables to create users and roles with permissions
	  too specific resources
	- Supports Multi-factor authentication & supports
	  single sign-on (SSO)

- Amazon GuardDuty
	- uses machine learning to look for malicious activity in AWS environment
	- combines cloudTrail event logs, VPC flow logs, S3 event logs
	  and DNS logs to continuouslt monitor and analyze all activity.
	- identifies issues like privilege escalation, exposed credentials, and
	  communication with malicious IP addresses and domains.
	- detects when Ec2 instances are serving malware or mining bitcoin

	- Also, detects access pattern anomalies such as API calls
	  in new regions, ...

- Amazon Macie
	- discovers and protects sensitive data stored in s3 buckets.
	- like personally-identifiable information, or personal health information,
	  through discovery jobs.
	- continously evaluates s3 buckets and alerts when bucket is
	  unencrypted, is publicly accessible, or is shared with aws accounts
	  outside the organization.

- AWS config
	- records and continuously evaluates your AWS resource configuration.
	- keeping a historical record of all changes to your resources, which is useful for compliance with legal requirements and your organization’s policies.
	- evaluates new and existing resources against rules that validate certain configurations.
	- Config is configured per region, so it’s essential to enable AWS Config in all regions to ensure all resources are recorded, including in regions where you don’t expect to create resources.

- AWS CloudTrail
	- tracks all activity in AWS environment.
	- It records all actions a user executes in the AWS console and all API calls as events.
	- You can view and search these events to identify unexpected or unusual requests in your AWS environment.
	- AWS CloudTrail Insights is an add-on to help identify unusual activity. It automatically analyzes your events and raises an event when it detects abnormal activity.
	- CloudTrail is enabled by default in all AWS accounts

- Security Hub
	- combines information from all the above services in a central, unified view. It collects data from all security services from multiple AWS accounts and regions, making it easier to get a complete view of your AWS security posture.


Application Security Tools
--------------------------
- Amazon Inspector
	- security assessment service for applications deployed on EC2.
	- assessments include network access, common vulnerabilities and exposures (CVEs), Center for Internet Security (CIS) benchmarks, and common best practices such as disabling root login for SSH and validating system directory permissions on your EC2 instances.
	- Based on agent application installed in EC2 VMs, Inspector
	  generates a report with a detailed list of security findings prioritized by severity.
	- Run Inspector as part of a gated check in deployment pipeline to assess your applications’ security before deploying to production.

- AWS Shield
	- fully-managed distributed denial-of-service (DDoS) protection service.
	- enabled by default as a free standard service with protection against common DDoS attacks against your AWS environment.

- AWS Web Application Firewall (WAF)
	- monitors and protects applications and APIs built on services such as CloudFront, API Gateway, and AppSync.
	- can block access to your endpoints based on different criteria such as the source IP address, the request’s origin country, values in headers and bodies, and more (i.e, you can enable rate limiting, only allowing a certain number of requests per IP

- AWS Secrets Manager
	- managed service where you can store and retrieve sensitive information such as database credentials, certificates, and tokens.
	- Use fine-grained permissions to specify exact actions an entity can perform on the secrets, such as creating, updating, deleting, or retrieving secrets.
	- Secrets Manager also supports automatic rotation for AWS services such as Amazon Relational Database Service (RDS).


start/stop ec2 using cloudwatch logs
=====================================
- I set an CloudWatch alarm and once it is triggered, it will notify an SNS topic.
- Then, this SNS topic will invoke a Lambda function, which can then start your EC2 instance.
- Then, Created an AWS Lambda function that starts the EC2 instance.
- And, configured the SNS topic to invoke your Lambda function when it receives messages.

AWS Local Zones
===============
- a new type of infrastructure that places compute, storage, database and other services
closer to end users and population centers so you can run applications that require single-digit
mili second latency and meet data residency requirements, when an AWS Region is not close enough.

Interview Questions Bank
========================
1. GUI is being called by a lot(millions of customers). You have a currency of lets say 100 requests per second and lets say your API response time should be less than a second and How do you build? what kind of API will you build ?and what's that model look like? just walk me through.

Ans : prepare on the tools AWS route 53, APIs tuning for 100 session


1a. What does the end point look like ?
2b. Do you know the parameter type that passes to the API, what kind of parameters you'll let the user pass through the GUI? What kind of method will you use for API calling?
Ans : customer ID , Get method


2. What kind of layers that you will build in your Python for taking the calls from UI? What is exception handling? How do you maintain the concurrency of your API?

Ans : {may be not 100% correct}---> research your own  correct answer
API token authentication we will do.
Parallel processing we will use to handle multiple requests.

2a. How do you handle parallel processing?
Ans : used a multi multi-processing library of Python.---> research your own  correct answer
        2a.a : what is a multi multi-processing library.
        2a.b : So how does "multiprocessing"  work ? You get a request for your end point and how would that multiprocessing library keep track of all that until you respond back to the UI ?
        2a.c: What happens if a thread (defect) gets stuck, what kind of exception you'll catch.
2a.d How about the query? You have a lot of records per customer that you need to query and then process right, so,how do you get the response quick? and what kind of querying that you use in your API?(because you can go and query and then filter the records and then you need less than a second response time,so how do you do that)?
Ans : --> research your own  correct answer

3. I have an array , an array will have both Positive and Negative numbers and if I want to get the closest 2 numbers of zero (ex: [3,7],13,19) and how do you get and what's the pseudo code that you write?

4. Do you have any experience in AWS ? What are the services hands on experience do you have ? (ex : EC2 , Lambda)
4.a : If I want to write lambda what is the start point for lambda ?
4.b : how do you invoke the lambda ? Where does the lambda start? What's that method name?
Ans : https://docs.aws.amazon.com/lambda/latest/dg/lambda-invocation.html --> research your own  correct answer

5. How long can you run Lambda ? What's the time limit for Lambda?
Ans : 15 minutes is the limit --> research your own  correct answer

6. If I want to invoke a lambda, let's say you wanted to pull the files from S3 and you are getting an issue, let's say 403 forbidden. What kind of issue could that be ? How do you debug that, what's your resolution?
7. If I am on the Linux box and want to write a python code to download some S3 files and do some processing and then upload files to S3, How do you write a script using python to do that CLI ratcheting.

ans : there is a library called bolt23, use access token/Ws --> research your own  correct answer
        7a. I still got the access forbidden/ what could have been the issue/lets say access token is good.
